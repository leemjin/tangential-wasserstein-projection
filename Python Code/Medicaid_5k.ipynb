{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06568c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import ot\n",
    "import cvxpy as cp\n",
    "\n",
    "# Supplementary Packages\n",
    "#import scipy.stats as stats\n",
    "#import seaborn as sns\n",
    "#import scipy.special as sps\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b38653",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532c1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baryc_proj(source, target, method):\n",
    "    \n",
    "    n1 = source.shape[0]\n",
    "    n2 = target.shape[0]   \n",
    "    p = source.shape[1]\n",
    "    a_ones, b_ones = np.ones((n1,)) / n1, np.ones((n2,)) / n2\n",
    "    \n",
    "    M = ot.dist(source, target)\n",
    "    M = M.astype('float64')\n",
    "    M /= M.max()\n",
    "    \n",
    "    if method == 'emd':\n",
    "        OTplan = ot.emd(a_ones, b_ones, M, numItermax = 1e7)\n",
    "        \n",
    "    elif method == 'entropic':\n",
    "        OTplan = ot.bregman.sinkhorn_stabilized(a_ones, b_ones, M, reg = 5*1e-3)\n",
    "    \n",
    "    # initialization\n",
    "    OTmap = np.empty((0, p))\n",
    "\n",
    "    for i in range(n1):\n",
    "        \n",
    "        # normalization\n",
    "        OTplan[i,:] = OTplan[i,:] / sum(OTplan[i,:])\n",
    "    \n",
    "        # conditional expectation\n",
    "        OTmap = np.vstack([OTmap, (target.T @ OTplan[i,:])])\n",
    "    \n",
    "    OTmap = np.array(OTmap)\n",
    "    \n",
    "    return(OTmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acacf3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSCreplicationV2(target, controls, method = 'emd'):\n",
    "    \n",
    "    n = target.shape[0]\n",
    "    d = target.shape[1]\n",
    "    J = len(controls)\n",
    "    \n",
    "    \n",
    "    # Barycentric Projection\n",
    "    G_list = []\n",
    "    proj_list = []\n",
    "    for i in range(len(controls)):\n",
    "        temp = baryc_proj(target, controls[i], method)\n",
    "        G_list.append(temp)\n",
    "        proj_list.append(temp - target)\n",
    "    \n",
    "    \n",
    "    # Obtain optimal weights\n",
    "    mylambda = cp.Variable(J)\n",
    "\n",
    "    objective = cp.Minimize(\n",
    "                    cp.sum(\n",
    "                    cp.sum(\n",
    "                    cp.sum([a*b for a,b in zip(mylambda, proj_list)])**2))/n\n",
    "                    )\n",
    "    \n",
    "    constraints = [mylambda >= 0, mylambda <= 1, cp.sum(mylambda) == 1]\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    weights = mylambda.value\n",
    "    replication = sum([a*b for a,b in zip(weights, G_list)])\n",
    "    \n",
    "    \n",
    "    return(weights, replication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ed796",
   "metadata": {},
   "source": [
    "## Medicare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eedd72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_medicaid(file_name, sample = False):\n",
    "    \n",
    "    columns = ['HINSCAID','EMPSTAT','UHRSWORK','INCWAGE']\n",
    "    df = pd.read_csv(file_name)[columns]\n",
    "    \n",
    "    if sample:\n",
    "        df = df.sample(5000, random_state = 31)\n",
    "    \n",
    "    return(np.array(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba4dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "medidata = []\n",
    "\n",
    "# check path\n",
    "for file in glob.glob(\"workingData/medicaid/*.csv\"):\n",
    "    medidata.append(read_medicaid(file, sample = True))\n",
    "\n",
    "medidata.insert(0, medidata.pop(12)) # Move Montana to front of list(why is mt 12?)\n",
    "medi_target = medidata[0]\n",
    "medi_controls = medidata[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62836076",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d84b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = t.time()\n",
    "\n",
    "weightsm, replicationm = DSCreplicationV2(medi_target, medi_controls)\n",
    "\n",
    "te = t.time() - ts\n",
    "# round integer columns\n",
    "replicationm[:,0:2] = replicationm[:,0:2].round(decimals = 0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa06ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medi_target[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abfd9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replicationm[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa016e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weightsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f55b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum((medi_target - replicationm)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d832c20",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3f366",
   "metadata": {},
   "source": [
    "### HINSCAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "5000 - sum(medi_target[:,0] == replicationm[:,0]) ## number of misses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4efad",
   "metadata": {},
   "source": [
    "### EMPSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad180027",
   "metadata": {},
   "outputs": [],
   "source": [
    "5000 - sum(medi_target[:,1] == replicationm[:,1]) ## number of misses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd761145",
   "metadata": {},
   "source": [
    "### UHRSWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152017f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(medi_target[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d8266",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(replicationm[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9902b",
   "metadata": {},
   "source": [
    "### INCWAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cca67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(medi_target[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb27706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(replicationm[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e423d",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* This replication was obtained using all 12 controls, all of them sampled without replacement at n=1500.\n",
    "* I think the replications are quite accurate; they seem to 'preserve the geometry' of the target distributions\n",
    "* The right tail of the INCWAGE column is not replicated as well. However, the point at the right end are outliers and I feel like all machine learning are prone to this level of error.\n",
    "* One thing to figure out is when to do the rounding. For this test run, binary columns are rounded after the replication, but I am unsure of the theoretical validity. One option is to round at the barycentric projection step, but in this case, we might have to round once more after we multiply the optimal weights.\n",
    "* This test run used 1500 observations, and it took 4 seconds to run on my personal laptop. If we were to utilize the GL cluster, I believe we can use even more than 10k observations. And another test run I did with 150 was worse than with 1500, so we might have even better replications with 10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a40c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c9196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
